{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating regions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up display area to show dataframe in jupyter qtconsole\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to the database\n",
    "engine = create_engine(f'postgresql://postgres:postgres@localhost:5432/HigherEducation')\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process CVS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUD-USPS ZIP Crosswalk Files\n",
    "https://www.huduser.gov/portal/datasets/usps_crosswalk.html#data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV files from current directory\n",
    "\n",
    "# create dataframe to hold all zip code data from files\n",
    "zips_df = pd.DataFrame(columns=['zipcode', 'cbsa_code'])\n",
    "\n",
    "# get current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# loop through current working directory ZIP code excel files\n",
    "for filename in os.listdir(path):\n",
    "    if filename.startswith('ZIP')&filename.endswith('.xlsx'):\n",
    "        df = pd.read_excel(os.path.join(path, filename), sheet_name=0, converters={'ZIP': str, 'zip': str})\n",
    "        df = df.rename(columns={'zip': 'zipcode','cbsa': 'cbsa_code', 'ZIP': 'zipcode', 'CBSA': 'cbsa_code'})[['zipcode', 'cbsa_code']]\n",
    "        zips_df = zips_df.append(df, ignore_index=True)\n",
    "\n",
    "print(zips_df.shape)\n",
    "\n",
    "# drop any duplicate rows\n",
    "zips_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# sort table by zip code\n",
    "zips_df.sort_values(by=['zipcode'], inplace=True)\n",
    "\n",
    "# reset the index\n",
    "zips_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(zips_df.shape)\n",
    "zips_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBSA data from Census\n",
    "https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2018/delineation-files/list1.xls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to hold all cbsa code data from files\n",
    "cbsa_columns = [ \n",
    "                 'cbsa_code', 'cbsa_title',\n",
    "                 'csa_code', 'title', \n",
    "                 'state_name', 'state_fips', \n",
    "                 'county', 'county_code'\n",
    "               ]\n",
    "\n",
    "cbsa_cols_renamed = {\n",
    "                        'CBSA Code': 'cbsa_code', 'CBSA Title': 'cbsa_title',\n",
    "                        'CSA Code': 'csa_code', 'CSA Title': 'title', \n",
    "                        'State Name': 'state_name', 'FIPS State Code': 'state_fips',\n",
    "                        'County/County Equivalent': 'county',\n",
    "                        'FIPS County Code': 'county_code'\n",
    "                    }\n",
    "\n",
    "cbsa_df = pd.DataFrame(columns=cbsa_columns)\n",
    "\n",
    "# get current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# loop through current working directory CBSA code excel files\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('_cbsa.xls'):\n",
    "        # read excel file and delete the last three rows containing text\n",
    "        df = pd.read_excel(os.path.join(path, filename), sheet_name=0, skiprows=2).iloc[:-3]\n",
    "        df = df.rename(columns=cbsa_cols_renamed)[cbsa_columns]\n",
    "        cbsa_df = cbsa_df.append(df, ignore_index=True)\n",
    "\n",
    "print(cbsa_df.shape)\n",
    "\n",
    "# drop any duplicate rows\n",
    "cbsa_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# replace missing csa titles with the cbsa title\n",
    "cbsa_df.title.fillna(cbsa_df.cbsa_title, inplace=True)\n",
    "\n",
    "# sort table by zip code\n",
    "cbsa_df.sort_values(by=['state_fips'], inplace=True)\n",
    "\n",
    "# reset the index\n",
    "cbsa_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# make sure that the codes are integers\n",
    "cbsa_int_cols = ['cbsa_code', 'csa_code', 'state_fips', 'county_code']\n",
    "cbsa_df.fillna({ col: 0 for col in cbsa_int_cols }, inplace=True)\n",
    "cbsa_df = cbsa_df.astype({ col: int for col in cbsa_int_cols })\n",
    "\n",
    "# delete unneeded columns\n",
    "del cbsa_df['cbsa_title']\n",
    "\n",
    "# drop rows with any missing data\n",
    "cbsa_df.dropna(how='any', inplace=True)\n",
    "\n",
    "# restructure columns\n",
    "cbsa_df = cbsa_df[['cbsa_code', 'title','state_name','state_fips']]\n",
    "\n",
    "print(cbsa_df.shape)\n",
    "cbsa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glassdoor Economic Research\n",
    "https://www.glassdoor.com/research/job-market-report-historical/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glassdoor Metro Areas and lookup keys\n",
    "areas = {\n",
    "    'Atlanta': 'Atlanta',\n",
    "    'Boston': 'Boston',\n",
    "    'Chicago': 'Chicago',\n",
    "    'Houston': 'Houston',\n",
    "    'Los Angeles': 'Los Angeles',\n",
    "    'New York': 'New York City',\n",
    "    'Philadelphia-Camden': 'Philadelphia',\n",
    "    'San Francisco': 'San Francisco',\n",
    "    'Seattle': 'Seattle',\n",
    "    'DC': 'Washington DC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create metro column in table with default string 'N/A'\n",
    "cbsa_df['metro'] = 'N/A'\n",
    "\n",
    "# loop through lookup keys\n",
    "for area,metro in areas.items():\n",
    "    # set glassdoor metro name where lookup key is found in CBSA title\n",
    "    cbsa_df.loc[cbsa_df.title.str.contains(area), 'metro'] = metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge transformations into one table for storing to the database\n",
    "regions_tbl = pd.merge(zips_df, cbsa_df, on=['cbsa_code'], how='left')\n",
    "\n",
    "# drop any duplicate rows\n",
    "regions_tbl.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop rows with any missing data\n",
    "regions_tbl.dropna(how='any', thresh=3, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "regions_tbl.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# make sure that the codes are integers\n",
    "regions_int_cols = ['cbsa_code', 'state_fips']\n",
    "regions_tbl.fillna({ col: 0 for col in regions_int_cols }, inplace=True)\n",
    "regions_tbl = regions_tbl.astype({ col: int for col in regions_int_cols })\n",
    "\n",
    "# set `zipcode` as the index\n",
    "regions_tbl.set_index('zipcode', inplace=True)\n",
    "\n",
    "# display table information\n",
    "print(regions_tbl.shape)\n",
    "regions_tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract table to CSV file\n",
    "# regions_tbl.to_csv('../../resources/regions.csv', sep=',', encoding='utf-8', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store table in database\n",
    "regions_tbl.to_sql(name='regions', con=engine, if_exists='replace', index=True, method='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query database table\n",
    "pd.read_sql('SELECT * FROM regions', con=engine, index_col='zipcode')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
