{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to the database\n",
    "engine = create_engine(f'postgresql://postgres:postgres@localhost:5432/HigherEducation')\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### college_names table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### College Scorecard Data Dictionary\n",
    "\n",
    "HIGHDEG = {\n",
    "\t0:\t'Non-degree-granting',\n",
    "\t1:\t'Certificate degree',\n",
    "\t2:\t'Associate degree',\n",
    "\t3:\t'Bachelors degree',\n",
    "\t4:\t'Graduate degree'\n",
    "}\n",
    "\n",
    "ICLEVEL = {\n",
    "\t1:\t'4-year',\n",
    "\t2:\t'2-year',\n",
    "\t3:\t'Less-than-2-year'\n",
    "}\n",
    "\n",
    "REGION = {\n",
    "\t0:\t'U.S. Service Schools',\n",
    "\t1:\t'New England (CT, ME, MA, NH, RI, VT)',\n",
    "\t2:\t'Mid East (DE, DC, MD, NJ, NY, PA)',\n",
    "\t3:\t'Great Lakes (IL, IN, MI, OH, WI)',\n",
    "\t4:\t'Plains (IA, KS, MN, MO, NE, ND, SD)',\n",
    "\t5:\t'Southeast (AL, AR, FL, GA, KY, LA, MS, NC, SC, TN, VA, WV)',\n",
    "\t6:\t'Southwest (AZ, NM, OK, TX)',\n",
    "\t7:\t'Rocky Mountains (CO, ID, MT, UT, WY)',\n",
    "\t8:\t'Far West (AK, CA, HI, NV, OR, WA)',\n",
    "\t9:\t'Outlying Areas (AS, FM, GU, MH, MP, PR, PW, VI)'\n",
    "}\n",
    "\n",
    "DISTANCEONLY = {\n",
    "\t0:\t'Not distance-education only',\n",
    "\t1:\t'Distance-education only'\n",
    "}\n",
    "    \n",
    "CURROPER = {\n",
    "\t0:\t'Not currently certified as an operating institution',\n",
    "\t1:\t'Currently certified as operating'\n",
    "}\n",
    "    \n",
    "SCHTYPE = { \n",
    "\t1:\t'Public',\n",
    "\t2:\t'Private, Nonprofit',\n",
    "\t3:\t'Private, For-profit'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set files path\n",
    "path = 'data/scorecard'\n",
    "\n",
    "# columns to select from datasets\n",
    "college_columns = [ 'UNITID','INSTNM','INSTURL',\\\n",
    "                    'CITY','STABBR','ZIP',\\\n",
    "                    'LATITUDE','LONGITUDE',\\\n",
    "                    'ST_FIPS', 'REGION','SCHTYPE',\\\n",
    "                    'HIGHDEG','CURROPER'\n",
    "                  ]\n",
    "\n",
    "# columns renamed as user friendly labels for use in database\n",
    "college_cols_renamed = {\n",
    "                        'UNITID'    : 'college_id',\n",
    "                        'INSTNM'    : 'name',\n",
    "                        'INSTURL'   : 'website',\n",
    "                        'SCHTYPE'   : 'schtype',\n",
    "                        'CITY'      : 'city',\n",
    "                        'STABBR'    : 'state',\n",
    "                        'ZIP'       : 'zipcode',\n",
    "                        'ST_FIPS'   : 'state_fips',\n",
    "                        'LATITUDE'  : 'latitude',\n",
    "                        'LONGITUDE' : 'longitude',\n",
    "                        'REGION'    : 'region'\n",
    "                       }\n",
    "# create an empty dataframe for storing the CSV files data\n",
    "college_names_df = pd.DataFrame() \n",
    "\n",
    "# loop through files in current directory\n",
    "for filename in os.listdir(path):\n",
    "    if 'MERGED' in filename:\n",
    "        year = filename[6:][:7]\n",
    "        df = pd.read_csv(os.path.join(path, filename), encoding='utf-8', low_memory=False)\n",
    "        df = df[college_columns]\n",
    "        try:\n",
    "            college_names_df = college_names_df.append(df, ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "# keep only the first 5 characters of the zip code\n",
    "college_names_df['ZIP'] = college_names_df['ZIP'].str[:5]\n",
    "\n",
    "cond1 = (college_names_df['CURROPER'] == 1)           # select currently operating schools\n",
    "cond2 = (college_names_df['HIGHDEG'] > 0)             # select degree granting schools only\n",
    "college_names_df = college_names_df[cond1 & cond2]    # filter data and save as updated dataframe\n",
    "\n",
    "# rename columns\n",
    "college_names_df = college_names_df.rename(columns=college_cols_renamed)\n",
    "\n",
    "# drop last two rows\n",
    "df_cols = len(college_names_df.columns)\n",
    "college_names_df.drop(college_names_df.iloc[:, df_cols-2:df_cols], inplace = True, axis = 1)\n",
    "\n",
    "# update region names using the data dictionary provided by College Scorecard\n",
    "college_names_df['region'] = college_names_df['region'].replace(REGION)\n",
    "college_names_df['schtype'] = college_names_df['schtype'].replace(SCHTYPE)\n",
    "\n",
    "# Import schools from Kaggle CSV\n",
    "schools_df = pd.read_csv('data/kaggle/salaries-by-region-id.csv', encoding='utf-8').iloc[:, 0:2]\n",
    "\n",
    "# drop any rows with a missing college id\n",
    "schools_df = schools_df[schools_df['UNITID'].isna() == False]\n",
    "\n",
    "# convert the college id to an integer\n",
    "schools_df = schools_df.astype({ 'UNITID': int })\n",
    "\n",
    "# rename the `UNITID` column to `college_id`\n",
    "schools_df.rename(columns={'UNITID': 'college_id', 'School Name': 'name'}, inplace=True)\n",
    "\n",
    "# drop duplicates\n",
    "schools_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# sort `college_id`\n",
    "schools_df.sort_values(by='college_id', inplace=True)\n",
    "\n",
    "# reset index\n",
    "schools_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Import school types from Kaggle CSV file\n",
    "school_types_df = pd.read_csv('data/kaggle/salaries-by-college-type-id.csv', encoding='utf-8').iloc[:, 0:3]\n",
    "\n",
    "# drop any rows with a missing college id\n",
    "school_types_df = school_types_df[school_types_df['UNITID'].isna() == False]\n",
    "\n",
    "# convert the college id to an integer\n",
    "school_types_df = school_types_df.astype({ 'UNITID': int })\n",
    "\n",
    "# rename the `UNITID` column to `college_id`\n",
    "school_types_df.rename(columns={'UNITID': 'college_id', 'School Name': 'name', 'School Type': 'type'}, inplace=True)\n",
    "\n",
    "# update school types of `Party` or `State` to `Public`\n",
    "school_types_df.loc[school_types_df['type'].isin(['Party','State']), 'type'] = 'Public'\n",
    "\n",
    "# drop duplicates\n",
    "school_types_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# remove bad data\n",
    "school_types_df = school_types_df.drop(school_types_df[(school_types_df['college_id']==233295) & (school_types_df['type']=='Public')].index)\n",
    "\n",
    "# sort by `college_id`\n",
    "school_types_df.sort_values(by='college_id', inplace=True)\n",
    "\n",
    "# reset index\n",
    "school_types_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# merge Kaggle schools data with Scorecard schools data\n",
    "college_names_tbl = pd.merge(schools_df.merge(school_types_df, on=['college_id','name'], how='left'),\n",
    "              college_names_df, on=['college_id'], how='left')\n",
    "\n",
    "# replace missing Kaggle school type with Scorecard school type\n",
    "college_names_tbl.type.fillna(college_names_tbl.schtype, inplace=True)\n",
    "\n",
    "# delete unneeded columns\n",
    "del college_names_tbl['schtype']\n",
    "del college_names_tbl['name_y']\n",
    "\n",
    "# rename `name` column\n",
    "college_names_tbl.rename(columns={'name_x': 'name'}, inplace=True)\n",
    "\n",
    "# set `college_id` as the index\n",
    "college_names_tbl.set_index('college_id', inplace=True)\n",
    "\n",
    "# store table in database\n",
    "college_names_tbl.to_sql(name='college_names', con=engine, if_exists='replace', index=True, method='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set files path\n",
    "path = 'data/cbsa'\n",
    "\n",
    "# specify crosswalk file load into table\n",
    "filename = 'zipcode_cbsa_crosswalk_2018.csv'\n",
    "zips_df = pd.read_csv(os.path.join(path, filename), encoding='utf-8', low_memory=False)\n",
    "\n",
    "# rename column\n",
    "zips_df = zips_df.rename(columns={ 'cbsacode': 'cbsa_code'})\n",
    "\n",
    "# drop any duplicate rows\n",
    "zips_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# sort table by zip code\n",
    "zips_df.sort_values(by=['zipcode'], inplace=True)\n",
    "\n",
    "# reset the index\n",
    "zips_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# cbsa dataframe column names\n",
    "cbsa_columns = [ \n",
    "                 'cbsa_code', 'cbsa_title',\n",
    "                 'csa_code', 'title', \n",
    "                 'state_name', 'state_fips', \n",
    "                 'county', 'county_code'\n",
    "               ]\n",
    "\n",
    "cbsa_cols_renamed = {\n",
    "                        'CBSA Code': 'cbsa_code', 'CBSA Title': 'cbsa_title',\n",
    "                        'CSA Code': 'csa_code', 'CSA Title': 'title', \n",
    "                        'State Name': 'state_name', 'FIPS State Code': 'state_fips',\n",
    "                        'County/County Equivalent': 'county',\n",
    "                        'FIPS County Code': 'county_code'\n",
    "                    }\n",
    "\n",
    "# create dataframe to hold all cbsa code data from files\n",
    "cbsa_df = pd.DataFrame(columns=cbsa_columns)\n",
    "\n",
    "# loop through current working directory CBSA code excel files\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('_cbsa.xls'):\n",
    "        # read excel file and delete the last three rows containing text\n",
    "        df = pd.read_excel(os.path.join(path, filename), sheet_name=0, skiprows=2, skipfooter=3)#.iloc[:-3]\n",
    "        df = df.rename(columns=cbsa_cols_renamed)[cbsa_columns]\n",
    "        cbsa_df = cbsa_df.append(df, ignore_index=True)\n",
    "\n",
    "\n",
    "# drop any duplicate rows\n",
    "cbsa_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# replace missing csa titles with the cbsa title\n",
    "cbsa_df.title.fillna(cbsa_df.cbsa_title, inplace=True)\n",
    "\n",
    "# sort table by zip code\n",
    "cbsa_df.sort_values(by=['state_fips'], inplace=True)\n",
    "\n",
    "# reset the index\n",
    "cbsa_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# make sure that the codes are integers\n",
    "cbsa_int_cols = ['cbsa_code', 'csa_code', 'state_fips', 'county_code']\n",
    "cbsa_df.fillna({ col: 0 for col in cbsa_int_cols }, inplace=True)\n",
    "cbsa_df = cbsa_df.astype({ col: int for col in cbsa_int_cols })\n",
    "\n",
    "# delete unneeded columns\n",
    "del cbsa_df['cbsa_title']\n",
    "\n",
    "# drop rows with any missing data\n",
    "cbsa_df.dropna(how='any', inplace=True)\n",
    "\n",
    "# restructure columns\n",
    "cbsa_df = cbsa_df[['cbsa_code', 'title','state_name','state_fips']]\n",
    "\n",
    "# Glassdoor Metro Areas and lookup keys\n",
    "areas = {\n",
    "    'Atlanta': 'Atlanta',\n",
    "    'Boston': 'Boston',\n",
    "    'Chicago': 'Chicago',\n",
    "    'Houston': 'Houston',\n",
    "    'Los Angeles': 'Los Angeles',\n",
    "    'New York': 'New York City',\n",
    "    'Philadelphia-Camden': 'Philadelphia',\n",
    "    'San Francisco': 'San Francisco',\n",
    "    'Seattle': 'Seattle',\n",
    "    'DC': 'Washington DC'\n",
    "}\n",
    "\n",
    "# create metro column in table with default string 'N/A'\n",
    "cbsa_df['metro'] = 'N/A'\n",
    "\n",
    "# loop through lookup keys\n",
    "for area,metro in areas.items():\n",
    "    # set glassdoor metro name where lookup key is found in CBSA title\n",
    "    cbsa_df.loc[cbsa_df.title.str.contains(area), 'metro'] = metro\n",
    "    \n",
    "# merge transformations into one table for storing to the database\n",
    "regions_tbl = pd.merge(zips_df, cbsa_df, on=['cbsa_code'], how='left')\n",
    "\n",
    "# drop any duplicate rows\n",
    "regions_tbl.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop rows with any missing data\n",
    "regions_tbl.dropna(how='any', thresh=3, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "regions_tbl.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# make sure that the codes are integers\n",
    "regions_int_cols = ['cbsa_code', 'state_fips']\n",
    "regions_tbl.fillna({ col: 0 for col in regions_int_cols }, inplace=True)\n",
    "regions_tbl = regions_tbl.astype({ col: int for col in regions_int_cols })\n",
    "\n",
    "# set `zipcode` as the index\n",
    "regions_tbl.set_index('zipcode', inplace=True)\n",
    "\n",
    "# store table in database\n",
    "regions_tbl.to_sql(name='regions', con=engine, if_exists='replace', index=True, method='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import National Salary For Each Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degreesTPB_df = pd.read_csv(r\"data/kaggle/degrees-that-pay-back.csv\")\n",
    "\n",
    "degreesTPB_df = degreesTPB_df.rename(columns={\"Undergraduate Major\": \"Majors\"})\n",
    "\n",
    "#Transform Salary to Float\n",
    "for col in degreesTPB_df.columns:\n",
    "    if 'Salary' in col:\n",
    "        degreesTPB_df[col] = degreesTPB_df[col].replace( '[\\$,)]','', regex=True ).astype(float)\n",
    "        \n",
    "#Drop Unnecessary Columns\n",
    "degreesTPB_df = degreesTPB_df.drop(columns=['Percent change from Starting to Mid-Career Salary', 'Mid-Career 10th Percentile Salary', 'Mid-Career 25th Percentile Salary', 'Mid-Career 75th Percentile Salary', 'Mid-Career 90th Percentile Salary'])\n",
    "\n",
    "#Use pandas to load csv converted DataFrame into database\n",
    "if_exists_param = 'replace'\n",
    "\n",
    "# set name of index\n",
    "degreesTPB_df.index.name = 'major_id'\n",
    "\n",
    "degreesTPB_df.to_sql(name='salaries_per_major', con=engine, if_exists=if_exists_param, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
